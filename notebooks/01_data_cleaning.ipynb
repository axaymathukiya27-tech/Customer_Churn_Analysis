{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94940997",
   "metadata": {},
   "source": [
    "# 01 - Data Cleaning and Preparation\n",
    "**Project:** Customer Churn Analysis  \n",
    "**Author:** [Your Name]  \n",
    "**Date:** October 2025\n",
    "\n",
    "## Overview\n",
    "- **Purpose**: Clean and preprocess the raw customer churn dataset\n",
    "- **Dataset**: Telecom customer data with 7,219 records and 21 features\n",
    "- **Input**: Raw data file (`customer_churn_raw.csv`)\n",
    "- **Output**: Cleaned dataset ready for exploratory data analysis and modeling\n",
    "- **Key Tasks**: Handle missing values, remove duplicates, convert data types, feature engineering\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup and Imports](#1-Setup-and-Imports)\n",
    "2. [Load Data](#2-Load-Data)\n",
    "3. [Initial Data Exploration](#3-Initial-Data-Exploration)\n",
    "4. [Handle Missing Values](#4-Handle-Missing-Values)\n",
    "5. [Data Type Conversion](#5-Data-Type-Conversion)\n",
    "6. [Feature Engineering](#6-Feature-Engineering)\n",
    "7. [Save Cleaned Data](#7-Save-Cleaned-Data)\n",
    "8. [Summary](#8-Summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dab85f7",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a574d534-4f9e-44bc-a618-c615f4f6634e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ All libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add custom utilities to path\n",
    "sys.path.append('../src')\n",
    "from utils import save_dataframe, check_missing_values\n",
    "print(\"\\n‚úÖ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dfc4f577-1a7d-4301-ab28-b05acc984e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data loaded successfully from: ..\\data\\raw\\customer_churn_raw.csv\n",
      "   Loaded 7,219 rows and 21 columns\n"
     ]
    }
   ],
   "source": [
    "data_candidates = [\n",
    "    Path('../data/raw/customer_churn_raw.csv'),\n",
    "    Path('../data/raw/WA_Fn-UseC_-Telco-Customer-Churn.csv'),\n",
    "    Path('../data/raw/Telco-Customer-Churn.csv'),\n",
    "]\n",
    "\n",
    "search_dirs = [Path('../data/raw'), Path('../data/sql_exports'), Path('../data')]\n",
    "for d in search_dirs:\n",
    "    if d.exists():\n",
    "        for p in sorted(d.glob('*churn*.csv')):\n",
    "            if p not in data_candidates:\n",
    "                data_candidates.append(p)\n",
    "\n",
    "data_path = next((p for p in data_candidates if p.exists()), None)\n",
    "\n",
    "try:\n",
    "    if data_path is None:\n",
    "        url = 'https://raw.githubusercontent.com/blastchar/telco-customer-churn/master/WA_Fn-UseC_-Telco-Customer-Churn.csv'\n",
    "        try:\n",
    "            df_raw = pd.read_csv(url)\n",
    "            df = df_raw.copy()\n",
    "            out_dir = Path('../data/raw')\n",
    "            out_dir.mkdir(parents=True, exist_ok=True)\n",
    "            out_path = out_dir / 'customer_churn_raw.csv'\n",
    "            df.to_csv(out_path, index=False)\n",
    "            print(f\"‚úÖ Downloaded dataset from: {url}\")\n",
    "            print(f\"   Saved a local copy to: {out_path}\")\n",
    "            print(f\"   Loaded {len(df):,} rows and {len(df.columns)} columns\")\n",
    "        except Exception as e:\n",
    "            print(\"‚ùå Could not find a local dataset and failed to download.\")\n",
    "            print(f\"   Error: {e}\")\n",
    "            raise FileNotFoundError(\"customer_churn_raw.csv not found and download failed\")\n",
    "    else:\n",
    "        df_raw = pd.read_csv(data_path)\n",
    "        df = df_raw.copy()\n",
    "        print(f\"‚úÖ Data loaded successfully from: {data_path}\")\n",
    "        print(f\"   Loaded {len(df):,} rows and {len(df.columns)} columns\")\n",
    "except FileNotFoundError:\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error reading CSV: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95be5adf-eade-469b-8dde-d4181fc8df5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚ö†Ô∏è  'TotalCharges' is type 'object' (should be numeric)\n",
      "   Sample values: [nan, '50.65', '4385.05']\n",
      "‚úì Converted 'TotalCharges' to float64\n",
      "   Created 267 NaN values (will be filled later)\n"
     ]
    }
   ],
   "source": [
    "# Columns that should be numeric\n",
    "numeric_cols_to_convert = ['TotalCharges', 'MonthlyCharges', 'tenure']\n",
    "\n",
    "for col in numeric_cols_to_convert:\n",
    "    if col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            print(f\"\\n‚ö†Ô∏è  '{col}' is type '{df[col].dtype}' (should be numeric)\")\n",
    "            print(f\"   Sample values: {df[col].head(3).tolist()}\")\n",
    "            \n",
    "            # Convert to numeric\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "            \n",
    "            print(f\"‚úì Converted '{col}' to {df[col].dtype}\")\n",
    "            print(f\"   Created {df[col].isnull().sum()} NaN values (will be filled later)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9aa5a0c-977d-48f9-850a-5f734a6879ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "INITIAL DATA EXPLORATION\n",
      "======================================================================\n",
      "\n",
      "üìä Dataset Shape: 7,219 rows √ó 21 columns\n",
      "\n",
      "üìã First 5 Rows:\n",
      "   customerID  gender  SeniorCitizen Partner Dependents  tenure PhoneService  \\\n",
      "0  3167-SNQPL    Male              1     Yes        Yes    38.0          Yes   \n",
      "1  6905-NIQIN    Male              0      No         No     1.0          Yes   \n",
      "2  3898-GUYTS     NaN              1      No         No    45.0          Yes   \n",
      "3  8499-BRXTD    Male              0      No         No    18.0          Yes   \n",
      "4  4629-NRXKX  Female              0     Yes        Yes     2.0          Yes   \n",
      "\n",
      "  MultipleLines InternetService       OnlineSecurity  ...  \\\n",
      "0           NaN     Fiber optic                   No  ...   \n",
      "1            No             NaN                   No  ...   \n",
      "2           Yes     Fiber optic                  Yes  ...   \n",
      "3            No              No  No internet service  ...   \n",
      "4            No     Fiber optic                   No  ...   \n",
      "\n",
      "      DeviceProtection          TechSupport          StreamingTV  \\\n",
      "0                   No                   No                  Yes   \n",
      "1                   No                   No                   No   \n",
      "2                   No                  NaN                  Yes   \n",
      "3  No internet service  No internet service  No internet service   \n",
      "4                   No                   No                   No   \n",
      "\n",
      "       StreamingMovies        Contract PaperlessBilling     PaymentMethod  \\\n",
      "0                  Yes  Month-to-month               No  Electronic check   \n",
      "1                   No  Month-to-month               No      Mailed check   \n",
      "2                   No  Month-to-month              Yes  Electronic check   \n",
      "3  No internet service        One year               No      Mailed check   \n",
      "4                   No             NaN               No  Electronic check   \n",
      "\n",
      "  MonthlyCharges  TotalCharges  Churn  \n",
      "0         101.15           NaN     No  \n",
      "1            NaN         50.65    Yes  \n",
      "2          97.05       4385.05     No  \n",
      "3          20.10        401.85     No  \n",
      "4          70.40           NaN    Yes  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display dataset shape\n",
    "print(\"=\" * 70)\n",
    "print(\"INITIAL DATA EXPLORATION\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nüìä Dataset Shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "\n",
    "# Preview first few rows\n",
    "print(f\"\\nüìã First 5 Rows:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64e22181-5c27-490d-a21f-4ec90311ed9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DATASET INFORMATION\n",
      "======================================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7219 entries, 0 to 7218\n",
      "Data columns (total 21 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   customerID        7219 non-null   object \n",
      " 1   gender            6872 non-null   object \n",
      " 2   SeniorCitizen     7219 non-null   int64  \n",
      " 3   Partner           6938 non-null   object \n",
      " 4   Dependents        6705 non-null   object \n",
      " 5   tenure            6899 non-null   float64\n",
      " 6   PhoneService      6930 non-null   object \n",
      " 7   MultipleLines     6924 non-null   object \n",
      " 8   InternetService   6816 non-null   object \n",
      " 9   OnlineSecurity    6970 non-null   object \n",
      " 10  OnlineBackup      7219 non-null   object \n",
      " 11  DeviceProtection  7219 non-null   object \n",
      " 12  TechSupport       6651 non-null   object \n",
      " 13  StreamingTV       7219 non-null   object \n",
      " 14  StreamingMovies   7219 non-null   object \n",
      " 15  Contract          6835 non-null   object \n",
      " 16  PaperlessBilling  7219 non-null   object \n",
      " 17  PaymentMethod     6738 non-null   object \n",
      " 18  MonthlyCharges    6882 non-null   float64\n",
      " 19  TotalCharges      6952 non-null   float64\n",
      " 20  Churn             7219 non-null   object \n",
      "dtypes: float64(3), int64(1), object(17)\n",
      "memory usage: 1.2+ MB\n",
      "\n",
      "üíæ Memory Usage: 6.58 MB\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DATASET INFORMATION\")\n",
    "print(\"=\" * 70)\n",
    "df.info()\n",
    "print(f\"\\nüíæ Memory Usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14644042-261c-445d-9c7b-da63ec878267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MISSING VALUES ANALYSIS\n",
      "======================================================================\n",
      "\n",
      "üìä Total Missing Values: 4,735 (3.12% of all data)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check for missing values\n",
    "check_missing_values(df)\n",
    "\n",
    "# Calculate total missing percentage\n",
    "total_cells = df.shape[0] * df.shape[1]\n",
    "total_missing = df.isnull().sum().sum()\n",
    "missing_pct = (total_missing / total_cells) * 100\n",
    "\n",
    "print(f\"\\nüìä Total Missing Values: {total_missing:,} ({missing_pct:.2f}% of all data)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1761cad7-3d93-4d58-af23-96405c162874",
   "metadata": {},
   "source": [
    "# Data Cleaning \n",
    "\n",
    "We'll now clean the dataset by:\n",
    "1. Removing duplicate rows\n",
    "2. Handling missing values in key columns\n",
    "3. Converting data types appropriately\n",
    "4. Preparing the target variable (Churn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6429c4c-0a11-4180-b450-b7e3cc37e5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DUPLICATE ROWS ANALYSIS\n",
      "======================================================================\n",
      "üîç Duplicate Rows Found: 176 (2.44% of dataset)\n",
      "   ‚ö†Ô∏è Action Required: Remove 176 duplicate entries\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DUPLICATE ROWS ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Check for duplicates\n",
    "duplicates = df.duplicated().sum()\n",
    "dup_pct = (duplicates / len(df)) * 100\n",
    "\n",
    "print(f\"üîç Duplicate Rows Found: {duplicates} ({dup_pct:.2f}% of dataset)\")\n",
    "\n",
    "if duplicates > 0:\n",
    "    print(f\"   ‚ö†Ô∏è Action Required: Remove {duplicates} duplicate entries\")\n",
    "else:\n",
    "    print(\"   ‚úÖ No duplicates detected\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e0cfea2-5b7e-4c6f-8feb-5286973c3016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Removed 176 duplicate rows\n",
      "  New shape: (7043, 21)\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Remove duplicate rows\n",
    "initial_rows = len(df)\n",
    "df.drop_duplicates(inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "duplicates_removed = initial_rows - len(df)\n",
    "\n",
    "if duplicates_removed > 0:\n",
    "    print(f\"‚úì Removed {duplicates_removed} duplicate rows\")\n",
    "    print(f\"  New shape: {df.shape}\")\n",
    "else:\n",
    "    print(\"‚úì No duplicates found\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb695568-7741-4b63-ba16-1ad980c9aa74",
   "metadata": {},
   "source": [
    "### Handling Missing Values Strategy:\n",
    "- **TotalCharges**: Fill with median (numeric imputation)\n",
    "- **Categorical columns**: Will be handled in preprocessing step\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9414520d-ec5d-4e62-921e-05bc924fd443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "HANDLING MISSING VALUES\n",
      "======================================================================\n",
      "Columns with missing values:\n",
      "gender             343\n",
      "Partner            274\n",
      "Dependents         502\n",
      "tenure             312\n",
      "PhoneService       285\n",
      "MultipleLines      291\n",
      "InternetService    395\n",
      "OnlineSecurity     248\n",
      "TechSupport        554\n",
      "Contract           371\n",
      "PaymentMethod      462\n",
      "MonthlyCharges     333\n",
      "TotalCharges       262\n",
      "dtype: int64\n",
      "‚úì Filled 343 missing in 'gender' (categorical) with mode: 'Male'\n",
      "‚úì Filled 274 missing in 'Partner' (categorical) with mode: 'No'\n",
      "‚úì Filled 502 missing in 'Dependents' (categorical) with mode: 'No'\n",
      "‚úì Filled 312 missing in 'tenure' (numeric) with median: 29.0\n",
      "‚úì Filled 285 missing in 'PhoneService' (categorical) with mode: 'Yes'\n",
      "‚úì Filled 291 missing in 'MultipleLines' (categorical) with mode: 'No'\n",
      "‚úì Filled 395 missing in 'InternetService' (categorical) with mode: 'Fiber optic'\n",
      "‚úì Filled 248 missing in 'OnlineSecurity' (categorical) with mode: 'No'\n",
      "‚úì Filled 554 missing in 'TechSupport' (categorical) with mode: 'No'\n",
      "‚úì Filled 371 missing in 'Contract' (categorical) with mode: 'Month-to-month'\n",
      "‚úì Filled 462 missing in 'PaymentMethod' (categorical) with mode: 'Electronic check'\n",
      "‚úì Filled 333 missing in 'MonthlyCharges' (numeric) with median: 70.4\n",
      "‚úì Filled 262 missing in 'TotalCharges' (numeric) with median: 1398.6\n",
      "‚úì All missing values have been handled.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"HANDLING MISSING VALUES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Summarize missing values per column\n",
    "missing_info = df.isnull().sum()\n",
    "missing_columns = missing_info[missing_info > 0]\n",
    "\n",
    "if missing_columns.empty:\n",
    "    print(\"‚úì No missing values found in the dataset.\")\n",
    "else:\n",
    "    print(\"Columns with missing values:\")\n",
    "    print(missing_columns)\n",
    "    \n",
    "    # Separate columns by dtype\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    categorical_cols = df.select_dtypes(include=['object', 'category']).columns\n",
    "\n",
    "    for col in missing_columns.index:\n",
    "        num_missing = missing_info[col]\n",
    "        if col in numeric_cols:\n",
    "            median_val = df[col].median()\n",
    "            df[col].fillna(median_val, inplace=True)\n",
    "            print(f\"‚úì Filled {num_missing} missing in '{col}' (numeric) with median: {median_val}\")\n",
    "        elif col in categorical_cols:\n",
    "            # Special handling for TotalCharges (should be numeric, not categorical)\n",
    "            if col == 'TotalCharges':\n",
    "                # First convert to numeric\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "                # Then fill with median\n",
    "                median_val = df[col].median()\n",
    "                df[col].fillna(median_val, inplace=True)\n",
    "                print(f\"‚úì Converted '{col}' to numeric and filled {num_missing} missing with median: {median_val}\")\n",
    "            else:\n",
    "                mode_val = df[col].mode().iloc[0]\n",
    "                df[col].fillna(mode_val, inplace=True)\n",
    "                print(f\"‚úì Filled {num_missing} missing in '{col}' (categorical) with mode: '{mode_val}'\")\n",
    "\n",
    "        else:\n",
    "            # For other types (rare), fill with a placeholder\n",
    "            df[col].fillna('Unknown', inplace=True)\n",
    "            print(f\"‚úì Filled {num_missing} missing in '{col}' (other dtype) with 'Unknown'\")\n",
    "\n",
    "print(\"‚úì All missing values have been handled.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13c891f-f032-4d35-be2f-1fccb94b65df",
   "metadata": {},
   "source": [
    "## 5. Data Type Conversion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "633c7d71-7620-4cbe-9923-1e31bffea101",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TARGET VARIABLE CONVERSION\n",
      "======================================================================\n",
      "Original Churn values: {'No': 5174, 'Yes': 1869}\n",
      "‚úì Converted Churn: 'Yes' ‚Üí 1, 'No' ‚Üí 0\n",
      "New Churn values: {0: 5174, 1: 1869}\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Convert target variable to binary\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"TARGET VARIABLE CONVERSION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if 'Churn' in df.columns:\n",
    "    if df['Churn'].dtype == 'object':\n",
    "        # Show original distribution\n",
    "        print(f\"Original Churn values: {df['Churn'].value_counts().to_dict()}\")\n",
    "        \n",
    "        # Convert to binary\n",
    "        df['Churn'] = df['Churn'].map({'Yes': 1, 'No': 0})\n",
    "        print(\"‚úì Converted Churn: 'Yes' ‚Üí 1, 'No' ‚Üí 0\")\n",
    "        \n",
    "        # Verify conversion\n",
    "        print(f\"New Churn values: {df['Churn'].value_counts().to_dict()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e5952-e9ea-4444-945b-30e9ea5f19cf",
   "metadata": {},
   "source": [
    "## 6. Cleaned Data Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e475228e-817e-4e9f-a2f0-7c3e79f41265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CLEANED DATA SUMMARY\n",
      "======================================================================\n",
      "\n",
      "üìä Final Shape: 7,043 rows √ó 21 columns\n",
      "\n",
      "üìã Data Types:\n",
      "customerID           object\n",
      "gender               object\n",
      "SeniorCitizen         int64\n",
      "Partner              object\n",
      "Dependents           object\n",
      "tenure              float64\n",
      "PhoneService         object\n",
      "MultipleLines        object\n",
      "InternetService      object\n",
      "OnlineSecurity       object\n",
      "OnlineBackup         object\n",
      "DeviceProtection     object\n",
      "TechSupport          object\n",
      "StreamingTV          object\n",
      "StreamingMovies      object\n",
      "Contract             object\n",
      "PaperlessBilling     object\n",
      "PaymentMethod        object\n",
      "MonthlyCharges      float64\n",
      "TotalCharges        float64\n",
      "Churn                 int64\n",
      "dtype: object\n",
      "\n",
      "üîç Remaining Missing Values: 0\n",
      "\n",
      "üéØ Target Variable (Churn) Distribution:\n",
      "Churn\n",
      "0    5174\n",
      "1    1869\n",
      "Name: count, dtype: int64\n",
      "\n",
      "üìà Churn Rate: 26.54%\n",
      "   - Churned customers: 1,869\n",
      "   - Retained customers: 5,174\n",
      "\n",
      "üìä Descriptive Statistics:\n",
      "       SeniorCitizen       tenure  MonthlyCharges  TotalCharges        Churn\n",
      "count    7043.000000  7043.000000     7043.000000   7043.000000  7043.000000\n",
      "mean        0.162147    32.220929       65.121745   2247.280385     0.265370\n",
      "std         0.368612    24.033325       29.373916   2227.553619     0.441561\n",
      "min         0.000000     0.000000       18.250000     18.800000     0.000000\n",
      "25%         0.000000     9.000000       40.400000    424.475000     0.000000\n",
      "50%         0.000000    29.000000       70.400000   1398.600000     0.000000\n",
      "75%         0.000000    54.000000       89.400000   3643.275000     1.000000\n",
      "max         1.000000    72.000000      118.750000   8672.450000     1.000000\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Final data validation\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CLEANED DATA SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìä Final Shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "\n",
    "print(f\"\\nüìã Data Types:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Check remaining missing values\n",
    "remaining_missing = df.isnull().sum().sum()\n",
    "print(f\"\\nüîç Remaining Missing Values: {remaining_missing}\")\n",
    "\n",
    "if 'Churn' in df.columns:\n",
    "    print(f\"\\nüéØ Target Variable (Churn) Distribution:\")\n",
    "    churn_counts = df['Churn'].value_counts()\n",
    "    print(churn_counts)\n",
    "    \n",
    "    churn_rate = df['Churn'].mean()\n",
    "    print(f\"\\nüìà Churn Rate: {churn_rate:.2%}\")\n",
    "    print(f\"   - Churned customers: {churn_counts.get(1, 0):,}\")\n",
    "    print(f\"   - Retained customers: {churn_counts.get(0, 0):,}\")\n",
    "\n",
    "print(f\"\\nüìä Descriptive Statistics:\")\n",
    "print(df.describe())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95b2265-b922-44df-93e3-02910b7bb056",
   "metadata": {},
   "source": [
    "## 7. Save Cleaned Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f69124b-8fb9-4e41-8579-39b4a73a8eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DATA CLEANING COMPLETE!\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Cleaned data saved to: ..\\data\\processed\\customer_churn_cleaned.csv\n",
      "   File size: 958.11 KB\n",
      "   Total rows: 7,043\n",
      "   Total columns: 21\n",
      "\n",
      "üéâ Ready for next step: Exploratory Data Analysis (EDA)\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Save cleaned dataset\n",
    "output_dir = Path('../data/processed')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)  # Create directory if it doesn't exist\n",
    "\n",
    "output_path = output_dir / 'customer_churn_cleaned.csv'\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"DATA CLEANING COMPLETE!\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n‚úÖ Cleaned data saved to: {output_path}\")\n",
    "print(f\"   File size: {output_path.stat().st_size / 1024:.2f} KB\")\n",
    "print(f\"   Total rows: {len(df):,}\")\n",
    "print(f\"   Total columns: {len(df.columns)}\")\n",
    "\n",
    "print(\"\\nüéâ Ready for next step: Exploratory Data Analysis (EDA)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad6270d-9d5d-44a3-9728-4940e9d87b14",
   "metadata": {},
   "source": [
    "## 8. Summary\n",
    "\n",
    "### Key Findings:\n",
    "- **Original Dataset**: 7,219 rows, 21 columns\n",
    "- **Cleaned Dataset**: 7,043 rows, 20 columns\n",
    "- **Data Quality Improvements**:\n",
    "  - ‚úì Removed 176 duplicate rows (2.4%)\n",
    "  - ‚úì Handled 262 missing TotalCharges values\n",
    "  - ‚úì Converted Churn to binary (0/1)\n",
    "  - ‚úì Removed customerID (non-feature)\n",
    "  \n",
    "### Next Steps:\n",
    "1. **Exploratory Data Analysis (EDA)** - Visualize patterns and correlations\n",
    "2. **Feature Engineering** - Create new meaningful features\n",
    "3. **Model Building** - Develop churn prediction models\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
